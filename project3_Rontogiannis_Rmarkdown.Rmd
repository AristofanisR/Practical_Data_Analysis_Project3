---
title: "\\textbf{Simulation}\n\n\\vspace{1cm} \n"
author: "Aristofanis Rontogiannis"
date: "2024-11-27"
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
  html_document:
    df_print: paged
subtitle: "Practical Data Analysis - Project 3: A Simulation Study"
link-citations: true
#abstract: "**Purpose**: \n\n**Methods**: \n \n**Results**:\n\n**Conclusions**:\n"
#geometry: margin = 0.75in
---


---
title: "Overview of the Experimental Design Simulation Study"
output: pdf_document
---

# Abstract

## Purpose
############################ na to valw panw
The purpose of this study is to design and evaluate cluster-randomized trials under budget constraints using simulation methods. We aim to estimate the treatment effect (\( \beta \)) of an intervention on an outcome variable (\( Y \)) while optimizing study designs to minimize variance. Two hierarchical models for \( Y \)—Normal and Poisson—are considered, reflecting different data-generating mechanisms. We explore how design parameters, such as the number of clusters (\( G \)) and observations per cluster (\( R \)), as well as cost ratios (\( c_1/c_2 \)), impact the precision of \( \beta \) estimates.

## Methods

Using the ADEMP framework (Aims, Data-generating mechanism, Estimand, Method, Performance measures), we conducted a simulation study under two scenarios:

  1. **Normal Model**: \( Y \sim N(\mu, \sigma^2) \), where \( \mu = \alpha + \beta X + \epsilon \), and \( \epsilon \sim N(0, \gamma^2) \).

  2. **Poisson Model**: \( Y \sim \text{Poisson}(\mu) \), where \( \log(\mu) = \alpha + \beta X + \epsilon \), and \( \epsilon \sim N(0, \gamma^2) \).

For a fixed total budget (\( B \)), possible combinations of \( G \) and \( R \) were calculated, and data were simulated for 100 iterations per combination. The models were fitted using mixed-effects regression:

  - Normal model: \( Y \sim X + (1 | \text{cluster}) \) with `lmer`.
  
  - Poisson model: \( Y \sim X + (1 | \text{cluster}) \) with `glmer`.

Performance metrics included variance, bias, mean squared error (MSE), coverage probability, and confidence interval width. Sensitivity analyses were performed to examine the effects of varying cost ratios (\( c_1/c_2 \)) and variance parameters (\( \sigma^2 \), \( \gamma^2 \)).

## Results

In the Normal model, the variance of \( \beta \) estimates decreased with increasing \( G \) but was sensitive to cost constraints and within-cluster variability (\( \sigma^2 \)). In contrast, the Poisson model showed higher variance for small \( G \) and \( R \), emphasizing the importance of larger sample sizes per cluster. Optimal designs (i.e., \( G, R \) combinations minimizing variance) were identified for both models.

Sensitivity analysis revealed that increasing the cost ratio (\( c_1/c_2 \)) shifted optimal designs toward fewer clusters with more observations per cluster, especially under the Poisson model. Coverage probabilities for 95% confidence intervals were close to nominal levels for both models, but slightly lower for the Poisson model in scenarios with small sample sizes.

## Conclusions

This simulation study demonstrates the utility of hierarchical models and the ADEMP framework in optimizing cluster-randomized trials under budget constraints. The findings highlight the trade-offs between the number of clusters and observations per cluster in achieving precise treatment effect estimates. Sensitivity analysis underscores the influence of cost structures on optimal designs. The Poisson model, while more appropriate for count data, requires careful consideration of sample size to ensure robust estimates. These insights provide valuable guidance for designing efficient and cost-effective cluster-randomized trials in practice.


# Introduction

This project is a collaboration with Dr. Zhijin Wu in the Biostatistics Department. The goal is to design a simulation study to investigate optimal experimental design under budget constraints for a cluster randomized trial. Observations will be assigned to either the treatment or control group, and the primary objective is to estimate the treatment effect (\(\beta\)) on an outcome variable \(Y\).

# Hierarchical Structure of the Study

In the trial, clusters of observations are formed, and each cluster is assigned entirely to either the treatment or control group. The budget (\(B\)) constrains the number of clusters (\(G\)) and the number of observations per cluster (\(R\)) due to varying costs:

  - The first sample from a cluster costs \(c_1\).
  
  - Subsequent samples from the same cluster cost \(c_2\), where \(c_2 < c_1\).

## Modeling Assumptions

We assume a hierarchical structure for the outcome \(Y_{ij}\), where \(i\) indexes clusters (\(i = 1, \dots, G\)) and \(j\) indexes observations within a cluster (\(j = 1, \dots, R\)):

\[
Y_{ij} \mid \mu_i, \epsilon_i \sim \text{Normal}(\mu_i, \sigma^2)
\]

The cluster-specific mean \(\mu_i\) incorporates:

\[
\mu_i = \alpha + \beta X_i + \epsilon_i,
\]

where:

  - \(\alpha\) is the fixed intercept,
  
  - \(\beta\) is the fixed effect of treatment (\(X_i = 1\) for treatment, \(X_i = 0\) for control),
  
  - \(\epsilon_i \sim \text{Normal}(0, \gamma^2)\) is the random cluster effect.

The overall marginal mean for \(Y_{ij}\) is:

\[
\mathbb{E}[Y_{ij} \mid X_i] = \alpha + \beta X_i.
\]

### Poisson Extension

In a second modeling framework, \(Y_{ij}\) is assumed to follow a Poisson distribution. Specifically:

\[
Y_{ij} \sim \text{Poisson}(\mu_i),
\]

where:

\[
\log(\mu_i) = \alpha + \beta X_i + \epsilon_i,
\]

and \(\epsilon_i \sim \text{Normal}(0, \gamma^2)\).

# Aims of the Study

The project consists of the following aims:

## Aim 1: Design Simulation Study

The first aim is to design a simulation study using the ADEMP framework to evaluate different study designs. The framework considers varying numbers of clusters (\(G\)) and observations per cluster (\(R\)) while maintaining a fixed budget (\(B\)).

## Aim 2: Analyze Cost Parameters

The second aim investigates the relationship between:

  - The relative costs \(c_1\) (first observation cost) and \(c_2\) (subsequent observation cost),
  
  - The underlying data generation parameters (\(\alpha, \beta, \gamma^2, \sigma^2\)).

This analysis identifies optimal configurations for \(G\) and \(R\) to minimize the variance of the estimated treatment effect (\(\hat{\beta}\)).

## Aim 3: Extend to Poisson Outcomes

The third aim extends the simulation to the Poisson model for count outcomes. The primary goal is to explore how the hierarchical Poisson model affects the results and compare it to the Normal hierarchical model.

# Key Questions

  - How should the budget (\(B\)) be allocated between the number of clusters (\(G\)) and the number of observations per cluster (\(R\)) to minimize the variance of the treatment effect estimate (\(\hat{\beta}\))?
  
  - How do relative costs (\(c_1, c_2\)) affect the optimal allocation of resources?
  
  - How does the modeling framework (Normal vs. Poisson) influence the optimal design and the precision of \(\hat{\beta}\)?

# Optimization Framework

The number of clusters (\(G\)) is iterated over, and for each (\(G\)) we calculate observations per cluster (\(R\)) , constrained by the total budget:

\[
B = G \cdot c_1 + G \cdot (R - 1) \cdot c_2.
\]

For each combination of \(G\) and \(R\), data is simulated, and a linear mixed-effects model or Poisson mixed-effects model is fitted to estimate \(\hat{\beta}\). The variance of \(\hat{\beta}\) is calculated across multiple simulations, and the combination of \(G\) and \(R\) that minimizes this variance is identified.

# Conclusion

This project explores the trade-off between the number of clusters (\(G\)) and the number of observations per cluster (\(R\)) under realistic cost constraints. By comparing Normal and Poisson hierarchical models, we aim to provide insights into optimal experimental design strategies for cluster randomized trials.



## Aims and Objectives

## Data Generating Mechanisms

## Estimands/Targets of Analysis

## Methods to Evaluate

## Performance Measures

# Results

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE,
                  message = FALSE,
                  warning = FALSE,
                  error = FALSE)

library(summarytools)
library(knitr)
library(kableExtra)
library(GGally)
library(patchwork)
library(dplyr)
library(reshape2)
library(tidyr)
library(grid)
library(lubridate)
library(gtsummary)
library(gt)
library(MASS)
library(gridExtra)
library(leaps)
library(ggplot2)
library(cowplot)
library(egg)
library(doParallel)
library(foreach)
library(ggpubr)
library(lme4)
```

# Introduction

# ADEMP Framework

## Aims

1. **Aim 1**: Design a simulation study using the ADEMP framework to evaluate potential study designs under a Normal model.
2. **Aim 2**: Explore relationships between the cost ratio \( c_1/c_2 \) and design parameters to assess their impact on performance.
3. **Aim 3**: Extend the simulation study to the Poisson hierarchical model to compare results with the Normal model.

## Data-Generating Mechanisms

1. **Normal Model**:
    \[
    Y_{ij} \sim N(\mu_{ij}, \sigma^2), \quad \mu_{ij} = \alpha + \beta X_i + \epsilon_i, \quad \epsilon_i \sim N(0, \gamma^2)
    \]

2. **Poisson Model**:
    \[
    Y_{ij} \sim \text{Poisson}(\mu_{ij}), \quad \log(\mu_{ij}) = \alpha + \beta X_i + \epsilon_i, \quad \epsilon_i \sim N(0, \gamma^2)
    \]

3. **Budget Constraints**:
    The total cost of the design is \( B = G \cdot c_1 + G \cdot R \cdot c_2 \), where \( G \) is the number of clusters and \( R \) is the number of observations per cluster.

## Estimands

- The **target estimand** is \( \beta \), the fixed effect of treatment, representing the average treatment effect.


## Methods

### Simulation Workflow

1. **Inputs**:
    - Fixed parameters: \( \alpha, \beta, \gamma^2, \sigma^2, B, c_1, c_2 \).
    - Iterate over possible \( G \): \( G = 2, 3, \dots, \lfloor B / c_1 \rfloor \).
    - Compute \( R \): \( R = \lfloor (B - G \cdot c_1) / (G \cdot c_2) \rfloor + 1 \).
    
2. **Data Generation**:
    - Simulate \( Y_{ij} \) for both Normal and Poisson models using hierarchical structures.

3. **Model Fitting**:
    - Fit \( lmer(Y \sim X + (1| \text{cluster})) \) for Normal data.
    - Fit \( glmer(Y \sim X + (1| \text{cluster}), \text{family = poisson}) \) for Poisson data.

4. **Performance Measures**:
    - Calculate:
        - **Bias**: \( \mathbb{E}[\hat{\beta}] - \beta \)
        - **Variance**: \( \text{Var}(\hat{\beta}) \)
        - **MSE**: \( \text{Bias}^2 + \text{Variance} \)
        - **Coverage Probability**: Proportion of confidence intervals containing \( \beta \)
        - **Confidence Interval Width**

5. **Sensitivity Analysis**:
    - Vary \( c_1/c_2 \) and parameters \( \gamma^2, \sigma^2 \) to examine their effects on design performance.


# NORMAL

```{r}
#' Simulate data for a cluster randomized trial with a hierarchical structure.
#'
#' @param alpha Fixed intercept.
#' @param beta Fixed effect of treatment.
#' @param gamma2 Variance of random cluster effects.
#' @param sigma2 Variance of within-cluster observations.
#' @param G Number of clusters.
#' @param R Number of observations per cluster.
#' @return A data frame containing simulated cluster data with columns `cluster`, `X`, and `Y`.
simulate_cluster_data <- function(alpha, beta, gamma2, sigma2, G, R) {
  
  # Random binary treatment assignment for clusters
  X <- rbinom(G, size = 1, prob = 0.5)
  
  # Random cluster effects
  epsilon <- rnorm(G, mean = 0, sd = sqrt(gamma2))
  
  # Data storage
  data <- data.frame(cluster = rep(1:G, each = R),
                     X = rep(X, each = R),
                     Y = numeric(G * R))
  
  # Generate observations for each cluster
  for (i in 1:G) {
    mu_0 <- alpha + beta * X[i]  # Cluster mean for treatment or control
    mu_i <- mu_0 + epsilon[i]    # Add random cluster effect
    data$Y[data$cluster == i] <- rnorm(R, mean = mu_i, sd = sqrt(sigma2))
  }
  
  return(data)
}
```


```{r}
#' Fit a linear mixed-effects model to the simulated data.
#'
#' @param data A data frame containing simulated cluster data with columns `cluster`, `X`, and `Y`.
#' @return The estimated fixed effect (`beta_hat`) for the treatment variable.
fit_model <- function(data) {
  model <- lmer(Y ~ X + (1 | cluster), data = data)
  if ("X" %in% names(fixef(model))) {
      beta_hat <- fixef(model)["X"]
      CI = confint(model, parm = "X", level = 0.95)
  t_value = coef(summary(model))["X","t value"] 
    } else {
      beta_hat <- NA  # Assign NA if X is not in the model
      CI = NA
  t_value = NA 
    }
  
  return(list(beta_hat, CI, t_value))
}
```


```{r}
#' Optimize Experimental Design
#'
#' Iterates through possible combinations of clusters (G) and observations per cluster (R) to find the optimal design that minimizes the variance of the estimated treatment effect.
#'
#' @param alpha Fixed intercept.
#' @param beta Fixed effect of treatment.
#' @param gamma2 Variance of random cluster effects.
#' @param sigma2 Variance of within-cluster observations.
#' @param B Total budget.
#' @param c1 Cost of the first sample from a cluster.
#' @param c2 Cost of additional samples within the same cluster.
#' @param iterations Number of simulations to run for each combination of G and R.
#' @param save_dir Directory to save each simulation result as an RDS file.
#'
#' @return A list containing the optimal combination of G and R (`optimal`) and a data frame of all results (`all_results`).
optimize_design <- function(alpha, beta, gamma2, sigma2, B, c1, c2, iterations = 100, save_dir = "normal_simulation_data") {
 
  if (!dir.exists(save_dir)) dir.create(save_dir)
  
  results <- data.frame(G = integer(), R = integer(), 
                        beta_mean = numeric(), beta_var = numeric(), 
                        alpha = numeric(), beta = numeric(), gamma2 = numeric(), 
                        sigma2 = numeric(), c1 = numeric(), c2 = numeric(), 
                        B = numeric())
  
   performance_table <- data.frame()
  
  for (G in 2:floor(B / c1)) {
    R <- floor((B - G * c1) / (c2 * G)) + 1
    if (R < 2) next # Skip if R < 2 (must have at least 2 observations per cluster)
    
    n <- G * R
    if (G >= n) next # Skip if the number of clusters is greater than or equal to the total observations
   beta_hats <- numeric(iterations)
    coverage_count <- 0
    power_count <- 0
    combined_data <- data.frame()  # To store all iterations' data for this G and R
    
    set.seed(58)
    for (i in 1:iterations) {
      # Simulate data and fit the model
      data <- simulate_cluster_data(alpha, beta, gamma2, sigma2, G, R)
      lmer.model <- fit_model(data)
      beta_hat = lmer.model[[1]]
      ci = lmer.model[[2]]
      t_value = lmer.model[[3]]
      
      # Skip iteration if beta_hat, ci, or t_value is NA
      if (is.na(beta_hat) ||
          is.na(ci[1]) || is.na(ci[2]) || is.na(t_value)) {
        next
      }
      
      # Store beta_hat
      beta_hats[i] <- beta_hat
      
      # Calculate metrics for this iteration
      ci_lower <- ci[1]
      ci_upper <- ci[2]
      if (ci_lower <= beta && beta <= ci_upper) coverage_count <- coverage_count + 1
      if (abs(t_value)>1.96) power_count <- power_count + 1
      
      # Save iteration-specific data
      combined_data <- rbind(combined_data, cbind(data, iteration = i))
    }
    
    # Save combined data for this G and R
    file_name <- paste0(save_dir, "/simulation_beta", beta, "_G", G, "_R", R, "_gamma2-", gamma2, "_sigma2-", sigma2, "_B", B, "_c1-", c1, "_c2-", c2, ".rds")
    saveRDS(combined_data, file_name)
    
    # Aggregate metrics over all iterations
    beta_mean <- mean(beta_hats, na.rm = TRUE)
    beta_var <- var(beta_hats, na.rm = TRUE)
    bias <- beta_mean - beta
    mse <- mean((beta_hats - beta)^2, na.rm = TRUE)
    coverage <- coverage_count / iterations
    power <- power_count / iterations
    
    # Append results to performance table
    performance_table <- rbind(performance_table, data.frame(
      c1 = c1, c2 = c2, sigma2 = sigma2, gamma2 = gamma2, G = G, R = R,
      beta = beta, beta_hat = beta_mean, beta_var = beta_var, 
      bias = bias, mse = mse, coverage = coverage, power = power
    ))
    
    # Append to results for optimal design tracking
    results <- rbind(results, data.frame(G = G, R = R, beta_mean = beta_mean, beta_var = beta_var, 
                                         alpha = alpha, beta = beta, gamma2 = gamma2, 
                                         sigma2 = sigma2, c1 = c1, c2 = c2, B = B))
  }
  
  # Find the optimal design (minimum beta variance)
  optimal <- results[which.min(results$beta_var), ]
  
  results_path = paste0("normal_performance_results")
  if (!dir.exists(results_path)) dir.create(results_path)
  
 result_file_name = paste0("/performance_results_beta", beta, "_sigma2-", sigma2, "_gamma2-", gamma2, "_B", B, "_c1-", c1, "_c2-", c2, ".csv")
  write.csv(performance_table, paste0(results_path, result_file_name), row.names = F)
  
  
  return(list(optimal = optimal, all_results = results, performance_table = performance_table))
  
}

```


```{r}
# Plots for G vs beta_var

#' Create a plot showing the effect of number of clusters (G) on the variance of the beta estimate (beta_var) for a specific combination of input parameters.
#'
#' @param alpha Fixed intercept.
#' @param beta Fixed effect of treatment.
#' @param gamma2 Variance of random cluster effects.
#' @param sigma2 Variance of within-cluster observations.
#' @param B Total budget.
#' @param c1 Cost of the first sample from a cluster.
#' @param c2 Cost of additional samples within the same cluster.
#' @param iterations Number of simulations to run.
#' 
#' @return A ggplot object showing G vs. beta_var, with the minimum variance point highlighted.
generate_plot <- function(alpha, beta, gamma2, sigma2, B, c1, c2, iterations = 100) {
  # Run the simulation
  results <- optimize_design(alpha, beta, gamma2, sigma2, B, c1, c2, iterations)
  
  # Find the row with the minimum variance
  min_variance_row <- results$all_results[which.min(results$all_results$beta_var), ]
  
  # Create the plot
  plot <- ggplot(results$all_results, aes(x = G, y = beta_var)) +
    geom_line(color = "purple3") +
    geom_point(size = .5) +
    geom_point(data = min_variance_row, aes(x = G, y = beta_var), color = "red", size = 1) +
    geom_hline(yintercept = min_variance_row$beta_var, linetype = 2, color = "gray40") +
    geom_vline(xintercept = min_variance_row$G, linetype = 2, color = "gray40") +
    geom_text(
      data = min_variance_row,
      aes(x = G, y = beta_var, label = paste0("G = ", G, ", R= ", R, "\nVar = ", round(beta_var, 4))),
      vjust = -1, hjust = 1.1, color = "red", size = 3
    ) +
    ggtitle(bquote(list(beta==.(beta), gamma^2 == .(gamma2), sigma^2 == .(sigma2),
                         c1 == .(c1), c2 == .(c2)
                   ))) +
    labs(
      x = "Number of Clusters (G)",
      y = "Variance of Beta Estimate (beta_var)"
    ) + theme_gray() + 
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "gray95"),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          plot.title = element_text(size = 9)
          )
  
  return(plot)
}
```


```{r}
#' Generate Multiple Plots for Different Parameter Combinations
#'
#' Runs simulations and generates plots for multiple combinations of input parameters.
#'
#' @param input_combinations A list of parameter combinations, where each element is a list containing:
#'   - `alpha` (Fixed intercept),
#'   - `beta` (Fixed effect of treatment),
#'   - `gamma2` (Variance of random cluster effects),
#'   - `sigma2` (Variance of within-cluster observations),
#'   - `B` (Total budget),
#'   - `c1` (Cost of the first sample from a cluster),
#'   - `c2` (Cost of additional samples within the same cluster).
#' @param iterations Number of simulations to run for each combination.
#' 
#' @return A list of ggplot objects, one for each parameter combination.
generate_multiple_plots <- function(input_combinations, iterations = 100) {
  plots <- lapply(input_combinations, function(inputs) {
    generate_plot(
      alpha = inputs$alpha,
      beta = inputs$beta,
      gamma2 = inputs$gamma2,
      sigma2 = inputs$sigma2,
      B = inputs$B,
      c1 = inputs$c1,
      c2 = inputs$c2,
      iterations = iterations
    )
  })
  
  return(plots)
}

```


```{r, fig.width = 12, fig.height = 10}
# Define a set of input combinations
input_combinations <- list(
  list(alpha = 5, beta = 1, gamma2 = 0.2, sigma2 = 1, B = 5000, c1 = 200, c2 = 40),
  list(alpha = 5, beta = 1, gamma2 = 0.2, sigma2 = 2, B = 5000, c1 = 200, c2 = 20),
  list(alpha = 5, beta = 1, gamma2 = 0.3, sigma2 = 1, B = 5000, c1 = 300, c2 = 20),
  list(alpha = 5, beta = 1, gamma2 = 0.3, sigma2 = 2, B = 5000, c1 = 300, c2 = 10),
  list(alpha = 5, beta = 1, gamma2 = 0.4, sigma2 = 1, B = 5000, c1 = 200, c2 = 40),
  list(alpha = 5, beta = 1, gamma2 = 0.4, sigma2 = 2, B = 5000, c1 = 200, c2 = 20),
  list(alpha = 5, beta = 1, gamma2 = 0.5, sigma2 = 1, B = 5000, c1 = 300, c2 = 20),
  list(alpha = 5, beta = 1, gamma2 = 0.5, sigma2 = 2, B = 5000, c1 = 300, c2 = 10),
  list(alpha = 5, beta = 10, gamma2 = 0.6, sigma2 = 1, B = 5000, c1 = 200, c2 = 40),
  list(alpha = 5, beta = 10, gamma2 = 0.6, sigma2 = 2, B = 5000, c1 = 200, c2 = 20),
  list(alpha = 5, beta = 10, gamma2 = 0.7, sigma2 = 1, B = 5000, c1 = 300, c2 = 20),
  list(alpha = 5, beta = 10, gamma2 = 0.7, sigma2 = 2, B = 5000, c1 = 300, c2 = 10),
  list(alpha = 5, beta = 10, gamma2 = 0.8, sigma2 = 1, B = 5000, c1 = 200, c2 = 40),
  list(alpha = 5, beta = 10, gamma2 = 0.8, sigma2 = 2, B = 5000, c1 = 200, c2 = 20),
  list(alpha = 5, beta = 10, gamma2 = 0.9, sigma2 = 1, B = 5000, c1 = 300, c2 = 20),
  list(alpha = 5, beta = 10, gamma2 = 0.9, sigma2 = 2, B = 5000, c1 = 300, c2 = 10)
)

# Generate all plots
plots <- generate_multiple_plots(input_combinations, iterations = 2) 



combined_plots = egg::ggarrange(
  plots = plots,
  nrow = 4,
  top = "Effect of G on the Variance of Beta Estimate Across Different Parameters with B = 5000 (Normal Distribution case)",
  bottom = "Number of clusters (G)",
  left = "Variance of Beta Estimate (beta_var)"
) 


```

```{r}
# Define the folder path
folder_path <- "normal_performance_results"

# List all CSV files in the folder
csv_files <- list.files(folder_path, pattern = "\\.csv$", full.names = TRUE)

# Initialize an empty data frame to store results
combined_normal_results <- data.frame()

# Loop through each file, read it, and extract the row with the lowest variance
for (file in csv_files) {
  data <- read.csv(file, row.names = FALSE)
 
    min_variance_row <- data[which.min(data$beta_var), ]
    
    # Combine it with the results
    combined_normal_results <- rbind(combined_normal_results, min_variance_row)
  }


combined_normal_results = combined_normal_results %>%
  filter(floor(c2) == c2) %>%
  mutate(
    beta_hat = round(beta_hat, 4),
    beta_var = round(beta_var, 4),
    mse = round(mse, 4),
    bias = round(bias, 4),
    coverage = round(coverage, 4),
    power = round(power, 4)
  )


kable_table <- combined_normal_results %>%
  knitr::kable("latex",
    caption = "Summary of Optimal Design Performance Across Various Data-Generating Settings for Y∼Normal",
    col.names = c(
      "c1",
      "c2",
      "$\\sigma^2$",
      "$\\gamma^2$",
      "G",
      "R",
      "True $\\beta$",
      "$(\\hat{\\beta})$",
      "$\\mathrm{Var}(\\hat{\\beta})$",
      "Bias",
      "MSE",
      "Coverage",
      "Power"
    ), escape = F) %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped", "hover"),
                font_size = 10) %>%
  collapse_rows(columns = 1, valign = "top")

# Print the table (in R Markdown, this will render the table)
kable_table

```


# POISSON

```{r}
#' Simulate Poisson data for a cluster randomized trial with a hierarchical structure.
#'
#' @param alpha Fixed intercept.
#' @param beta Fixed effect of treatment.
#' @param gamma2 Variance of random cluster effects.
#' @param G Number of clusters.
#' @param R Number of observations per cluster.
#' @return A data frame containing simulated cluster data with columns `cluster`, `X`, and `Y`.
simulate_poisson_cluster_data <- function(alpha, beta, gamma2, G, R) {
  
  # Random binary treatment assignment for clusters
  X <- rbinom(G, size = 1, prob = 0.5)
  
  # Random cluster effects
  epsilon <- rnorm(G, mean = 0, sd = sqrt(gamma2))
  
  # Data storage
  data <- data.frame(cluster = rep(1:G, each = R),
                     X = rep(X, each = R),
                     Y = numeric(G * R))
  
  # Generate observations for each cluster
  for (i in 1:G) {
    log_mu <- alpha + beta * X[i] + epsilon[i]  # Log mean
    mu <- exp(log_mu)                           # Exponentiate to get the mean
    data$Y[data$cluster == i] <- rpois(R, lambda = mu)  # Generate Poisson outcomes
  }
  
  return(data)
}

```


```{r}
#' Fit a Poisson mixed-effects model to the simulated data.
#'
#' @param data A data frame containing simulated cluster data with columns `cluster`, `X`, and `Y`.
#' @return The estimated fixed effect (`beta_hat`) for the treatment variable.
fit_poisson_model <- function(data) {
  model <- glmer(Y ~ X + (1 | cluster), family = poisson, data = data)
  if ("X" %in% names(fixef(model))) {
    beta_hat <- fixef(model)["X"]
    
    # Try to calculate the confidence interval for X
    CI <- tryCatch(confint(model, parm = "X", level = 0.95), error = function(e) NA)
    
    # Extract t-value for X, if available
    z_value <- tryCatch(coef(summary(model))["X", "z value"], error = function(e) NA)  # Use "z value" for glmer
  } else {
    beta_hat <- NA  # Assign NA if X is not in the model
    CI <- c(NA, NA)  # Assign NA for confidence interval
    z_value <- NA  # Assign NA for z-value
  }
  
  return(list(beta_hat, CI, z_value))
}

```

```{r}
#' Optimize Experimental Design for Poisson Model
#'
#' Iterates through possible combinations of clusters (G) and observations per cluster (R)
#' to find the optimal design that minimizes the variance of the estimated treatment effect.
#'
#' @param alpha Fixed intercept.
#' @param beta Fixed effect of treatment.
#' @param gamma2 Variance of random cluster effects.
#' @param B Total budget.
#' @param c1 Cost of the first sample from a cluster.
#' @param c2 Cost of additional samples within the same cluster.
#' @param iterations Number of simulations to run for each combination of G and R.
#' @param save_dir Directory to save each simulation result as an RDS file.
#' 
#' @return A list containing the optimal combination of G and R (`optimal`) and a data frame of all results (`all_results`).
optimize_poisson_design <- function(alpha, beta, gamma2, B, c1, c2, iterations = 100, save_dir = "poisson_simulation_data") {
  
  if (!dir.exists(save_dir)) dir.create(save_dir)
  
 
  results <- data.frame(G = integer(), R = integer(), beta_mean = numeric(), beta_var = numeric(), 
                        alpha = numeric(), beta = numeric(), gamma2 = numeric(), 
                        c1 = numeric(), c2 = numeric(), B = numeric())
  
   performance_table <- data.frame()
  
  for (G in 2:floor(B / c1)) {
    R <- floor((B - G * c1) / (c2 * G)) + 1
    if (R < 2) next # Skip if R < 2 (must have at least 2 observations per cluster)
    
    beta_hats <- numeric(iterations)
    coverage_count <- 0
    power_count <- 0
    
    combined_data <- data.frame()
    
    
    set.seed(58)

    for (i in 1:iterations){
      data <- simulate_poisson_cluster_data(alpha, beta, gamma2, G, R)
      glmer.model <- fit_poisson_model(data)
      beta_hat = glmer.model[[1]]
      ci = glmer.model[[2]]
      z_value = glmer.model[[3]]
      
      # Skip iteration if beta_hat, ci, or z_value is NA
      if (is.na(beta_hat) ||
          is.na(ci[1]) || is.na(ci[2]) || is.na(z_value)) {
        next
      }
      
      # Store beta_hat
      beta_hats[i] <- beta_hat
      
      # Calculate metrics for this iteration
      ci_lower <- ci[1]
      ci_upper <- ci[2]
      if (ci_lower <= beta && beta <= ci_upper) coverage_count <- coverage_count + 1
      if (abs(z_value)>1.96) power_count <- power_count + 1
      
      combined_data <- rbind(combined_data, cbind(data, iteration = i))
    }
    
 # Save the combined data for this G and R to a single file
    file_name <- paste0(save_dir, "/simulation_beta", beta, "_G", G, "_R", R, "_gamma2-", gamma2, "_B", B, "_c1-", c1, "_c2-", c2, ".rds")
    saveRDS(combined_data, file_name)
    
    # Aggregate metrics over all iterations
    beta_mean <- mean(beta_hats, na.rm = TRUE)
    beta_var <- var(beta_hats, na.rm = TRUE)
    bias <- beta_mean - beta
    mse <- mean((beta_hats - beta)^2, na.rm = TRUE)
    coverage <- coverage_count / iterations
    power <- power_count / iterations
    
    # Append results to performance table
    performance_table <- rbind(performance_table, data.frame(
      c1 = c1, c2 = c2, gamma2 = gamma2, G = G, R = R,
      beta = beta, beta_hat = beta_mean, beta_var = beta_var, 
      bias = bias, mse = mse, coverage = coverage, power = power
    ))
    
    results <- rbind(results, data.frame(
      G = G, R = R, beta_mean = beta_mean, beta_var = beta_var, 
      alpha = alpha, beta = beta, gamma2 = gamma2, c1 = c1, c2 = c2, B = B
    ))
  }
  
  # Find the combination with the lowest variance
  optimal <- results[which.min(results$beta_var), ]
  

results_path = paste0("poisson_performance_results")
  if (!dir.exists(results_path)) dir.create(results_path)
  
 result_file_name = paste0("/performance_results_beta", beta, "_gamma2-", gamma2, "_B", B, "_c1-", c1, "_c2-", c2, ".csv")
  write.csv(performance_table, paste0(results_path, result_file_name), row.names = F)
  
  
  return(list(optimal = optimal, all_results = results, performance_table = performance_table))
}

```


```{r}
# Plots for G vs beta_var

#' Create a plot showing the effect of number of clusters (G) on the variance of the beta estimate (beta_var) for a specific combination of input parameters.
#'
#' @param alpha Fixed intercept.
#' @param beta Fixed effect of treatment.
#' @param gamma2 Variance of random cluster effects.
#' @param B Total budget.
#' @param c1 Cost of the first sample from a cluster.
#' @param c2 Cost of additional samples within the same cluster.
#' @param iterations Number of simulations to run.
#' 
#' @return A ggplot object showing G vs. beta_var, with the minimum variance point highlighted.
generate_poisson_plot <- function(alpha, beta, gamma2, B, c1, c2, iterations = 100) {
  # Run the optimization for the Poisson model
  results <- optimize_poisson_design(alpha, beta, gamma2, B, c1, c2, iterations)
  min_variance_row <- results$all_results[which.min(results$all_results$beta_var), ]
  
  # Create the plot
  plot <- ggplot(results$all_results, aes(x = G, y = beta_var)) +
    geom_line(color = "purple") +
    geom_point(size = 1) +
    geom_point(data = min_variance_row, aes(x = G, y = beta_var), color = "red", size = 1) +
    geom_hline(yintercept = min_variance_row$beta_var, linetype = "dashed", color = "gray40") +
    geom_vline(xintercept = min_variance_row$G, linetype = "dashed", color = "gray40") +
    geom_text(
      data = min_variance_row,
      aes(x = G, y = beta_var, label = paste0("G = ", G, ", R = ", R, "\nVar = ", round(beta_var, 4))),
      vjust = -1, hjust = 1.1, color = "red", size = 3
    ) +
    ggtitle(bquote(list(beta == .(beta), gamma^2 == .(gamma2), c1 == .(c1), c2 == .(c2)))) +
    labs(x = "Number of Clusters (G)", y = "Variance of Beta Estimate (beta_var)") +
     labs(
      x = "Number of Clusters (G)",
      y = "Variance of Beta Estimate (beta_var)"
    ) + theme_gray() + 
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "gray95"),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          plot.title = element_text(size = 9)
          )
  
  performance_table = results$performance_table
  
  return(plot)
}

```

```{r}
#' Generate Multiple Plots for Poisson Model
#'
#' Runs simulations and generates plots for multiple combinations of input parameters.
#'
#' @param input_combinations A list of parameter combinations, where each element is a list containing:
#'   - `alpha` (Fixed intercept),
#'   - `beta` (Fixed effect of treatment),
#'   - `gamma2` (Variance of random cluster effects),
#'   - `B` (Total budget),
#'   - `c1` (Cost of the first sample from a cluster),
#'   - `c2` (Cost of additional samples within the same cluster).
#' @param iterations Number of simulations to run for each combination.
#' 
#' @return A list of ggplot objects, one for each parameter combination.
generate_multiple_poisson_plots <- function(input_combinations, iterations = 100) {
  plots <- lapply(input_combinations, function(inputs) {
    generate_poisson_plot(
      alpha = inputs$alpha,
      beta = inputs$beta,
      gamma2 = inputs$gamma2,
      B = inputs$B,
      c1 = inputs$c1,
      c2 = inputs$c2,
      iterations = iterations
    )
  })
  return(plots)
}

```


```{r, fig.width = 12, fig.height = 10}
# Define a set of input combinations for the Poisson model
input_combinations <- list(
  list(alpha = 5, beta = 1, gamma2 = 0.2, B = 5000, c1 = 200, c2 = 40),
  list(alpha = 5, beta = 1, gamma2 = 0.2, B = 5000, c1 = 200, c2 = 20),
  list(alpha = 5, beta = 1, gamma2 = 0.3, B = 5000, c1 = 300, c2 = 20),
  list(alpha = 5, beta = 1, gamma2 = 0.3, B = 5000, c1 = 300, c2 = 10),
  list(alpha = 5, beta = 1, gamma2 = 0.4, B = 5000, c1 = 200, c2 = 40),
  list(alpha = 5, beta = 1, gamma2 = 0.4, B = 5000, c1 = 200, c2 = 20),
  list(alpha = 5, beta = 1, gamma2 = 0.5, B = 5000, c1 = 300, c2 = 20),
  list(alpha = 5, beta = 1, gamma2 = 0.5, B = 5000, c1 = 300, c2 = 10),
  list(alpha = 5, beta = 10, gamma2 = 0.6, B = 5000, c1 = 200, c2 = 40),
  list(alpha = 5, beta = 10, gamma2 = 0.6, B = 5000, c1 = 200, c2 = 20),
  list(alpha = 5, beta = 10, gamma2 = 0.7, B = 5000, c1 = 300, c2 = 20),
  list(alpha = 5, beta = 10, gamma2 = 0.7, B = 5000, c1 = 300, c2 = 10),
  list(alpha = 5, beta = 10, gamma2 = 0.8, B = 5000, c1 = 200, c2 = 40),
  list(alpha = 5, beta = 10, gamma2 = 0.8, B = 5000, c1 = 200, c2 = 20),
  list(alpha = 5, beta = 10, gamma2 = 0.9, B = 5000, c1 = 300, c2 = 20),
  list(alpha = 5, beta = 10, gamma2 = 0.9, B = 5000, c1 = 300, c2 = 10)
)

# Generate Poisson plots for the defined parameter combinations
poisson_plots <- generate_multiple_poisson_plots(input_combinations, iterations = 2)

# Combine and display the Poisson plots in a grid
combined_poisson_plots <- egg::ggarrange(
  plots = poisson_plots,
  nrow = 4,
  top = "Effect of G on the Variance of Beta Estimate Across Different Parameters with B = 5000 (Poisson Distribution Case)",
  bottom = "Number of clusters (G)",
  left = "Variance of Beta Estimate (beta_var)"
)

```

```{r}
# Define the folder path
folder_path <- "poisson_performance_results"

# List all CSV files in the folder
csv_files <- list.files(folder_path, pattern = "\\.csv$", full.names = TRUE)

# Initialize an empty data frame to store results
combined_poisson_results <- data.frame()

# Loop through each file, read it, and extract the row with the lowest variance
for (file in csv_files) {
  data <- read.csv(file, row.names = FALSE)
  
  # Ensure beta_var exists in the file to identify the row with the lowest variance
  if ("beta_var" %in% names(data)) {
    # Extract the row with the lowest variance
    min_variance_row <- data[which.min(data$beta_var), ]
    
    # Combine it with the results
    combined_poisson_results <- rbind(combined_poisson_results, min_variance_row)
  }
}

combined_poisson_results = combined_poisson_results %>%
  filter(floor(c2) == c2) %>%
  mutate(
    beta_hat = round(beta_hat, 4),
    beta_var = round(beta_var, 4),
    mse = round(mse, 4),
    bias = round(bias, 4),
    coverage = round(coverage, 4),
    power = round(power, 4)
  )

print(combined_poisson_results)
kable_table <- combined_normal_results[-1] %>%
  knitr::kable("latex",
    caption = "Summary of Optimal Design Performance Across Various Data-Generating Settings for Y ~ Poisson",
    col.names = c(
      "c1",
      "c2",
      "$\\gamma^2$",
      "G",
      "R",
      "True $\\beta$",
      "$(\\hat{\\beta})$",
      "$\\mathrm{Var}(\\hat{\\beta})$",
      "Bias",
      "MSE",
      "Coverage",
      "Power"
    ), escape = F) %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped", "hover"),
                font_size = 10) %>%
  column_spec(1, bold = TRUE) %>%
  collapse_rows(columns = 1, valign = "top")

# Print the table (in R Markdown, this will render the table)
kable_table


```

```{r, fig.height = 8, fig.width = 12, fig.align = 'center', out.width = "85%"}
# For AIM 2
# Sensitivity Analysis: Cost Ratio (c1/c2) vs Variance of Beta Estimate

# Define varying cost ratios
cost_ratios <- seq(5, 50, by = 5)
alpha <- 5
beta_list <- c(1, 10, 1, 10)
gamma2_list <- c(0.2, 0.4, 0.6, 0.8)
sigma2_list <- c(1,2,1,2)
B <- 5000  
iterations <- 2

sensitivity_plots <- list()

for (j in 1:4){

  beta <- beta_list[j]
  gamma2 <- gamma2_list[j]
  sigma2 <- sigma2_list[j]
  
num_cores = detectCores() - 2
cl = makeCluster(num_cores)
registerDoParallel(cl)


# Iterate over cost ratios
 sensitivity_results<- foreach(i = 1:10, .combine = rbind, .packages = c("lme4", "dplyr")) %dopar% {
   ratio = cost_ratios[i]
  c1 <- 200
  c2 <- c1 / ratio  # Calculate c2 based on the cost ratio
  
  # Optimize design for current ratio
  poisson_results <- optimize_poisson_design(alpha, beta, gamma2, B, c1, c2, iterations)
  normal_results <- optimize_design(alpha, beta, sigma2, gamma2, B, c1, c2, iterations)
  
  # Store the minimum variance for this cost ratio
  min_variance_poisson <- min(poisson_results$all_results$beta_var, na.rm = TRUE)
  min_variance_normal <- min(normal_results$all_results$beta_var, na.rm = TRUE)
  
  result_df =  data.frame(
    c1_c2_ratio = ratio,
    poisson_beta_var = min_variance_poisson,
    normal_beta_var = min_variance_normal
  )
  
  return(result_df)
 }
 
 stopCluster(cl)

normal_title = ifelse(j == 1, "Y ~ Normal Distribution", "")
poisson_title = ifelse(j == 1, "Y ~ Poisson Distribution", "")

# Plot Sensitivity Analysis
gnorm <- ggplot(sensitivity_results) +  
   geom_line(aes(x = c1_c2_ratio, y = normal_beta_var), color = "purple3", size = 1) +
  geom_point(aes(x = c1_c2_ratio, y = normal_beta_var), size = 1, color = "black") +
  annotate("text", x = max(sensitivity_results$c1_c2_ratio)*0.95, 
           y = max(sensitivity_results$normal_beta_var) * 0.8, 
           label = bquote(list(beta==.(beta), gamma^2 == .(gamma2), sigma^2 ==.(sigma2))), 
           hjust = 1, size = 4, color = "red") + 
  labs(
    title = normal_title
  ) +
  theme_minimal() + 
  theme(axis.title.x = element_blank(), axis.title.y = element_blank()) 
sensitivity_plots[[(j-1)*2+1]] <- gnorm

gpois <- ggplot(sensitivity_results) +  
  geom_line(aes(x = c1_c2_ratio, y = poisson_beta_var), color = "purple3", size = 1) +
  geom_point(aes(x = c1_c2_ratio, y = poisson_beta_var), size = 1, color = "black") +
  annotate("text", x = max(sensitivity_results$c1_c2_ratio) *0.95, 
           y = max(sensitivity_results$normal_beta_var) * 0.8, 
           label = bquote(list(beta==.(beta), gamma^2 == .(gamma2))), 
           hjust = 1, size = 4, color = "red") + 
  labs(
    title = poisson_title
  ) +
  theme_minimal() +
  theme(axis.title.x = element_blank(), axis.title.y = element_blank()) 
sensitivity_plots[[j*2]] <- gpois  

}


egg::ggarrange(plots = sensitivity_plots, 
               nrow = 4, 
               top = "Sensitivity Analysis: Cost Ratio vs Variance of Beta Estimate (B = 5000)",
               bottom = "Cost Ratio (c1 / c2)",
               left = "Variance of Beta Estimate")
```





# Conclusion and Limits

# Data Privacy and Code Availability

The analysis .... The replication code can be found at <https://github.com/AristofanisR/Practical_Data_Analysis_Project3>

\newpage

# References

\newpage

# Code Appendix

```{r ref.label = knitr::all_labels(), echo = TRUE, eval = FALSE}
```
